# Complete Parsing Architecture Report
## Data Lineage Parser v4.3.1 - Full System Analysis

**Generated**: 2025-11-12
**Status**: üî¥ **CRITICAL - 99% Failure Rate**
**Root Cause**: Architectural regression in commit `27a3d63` ("WARN mode breakthrough")

---

## Table of Contents

1. [Overview](#overview)
2. [Complete Parsing Flow](#complete-parsing-flow)
3. [Phase-by-Phase Analysis](#phase-by-phase-analysis)
4. [Architecture Evolution](#architecture-evolution)
5. [Current Issues](#current-issues)
6. [Test Results](#test-results)
7. [Recommendations](#recommendations)

---

## Overview

### System Purpose

Extract data lineage (inputs/outputs) from T-SQL stored procedures for visualization in a React Flow dependency graph.

### Input
- T-SQL stored procedure DDL text (CREATE PROC ... AS BEGIN ... END)
- 515 stored procedures in test database
- Average DDL length: ~5,000-15,000 characters

### Output
- **Inputs** (sources): Tables/views the SP reads from
- **Outputs** (targets): Tables the SP writes to
- **Confidence score**: 0, 75, 85, or 100 based on completeness
- **SP calls**: Other stored procedures called
- **Function calls**: UDFs used (v4.3.0 feature)

### Current Performance
- **Success rate**: ~1% (2 out of 515 SPs)
- **Parsing time**: 180+ seconds (timeout)
- **Average confidence**: 0.0 (failure)
- **User impact**: Empty dependency graph, no usable lineage data

---

## Complete Parsing Flow

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INPUT: T-SQL Stored Procedure DDL                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 1: SQL Preprocessing                                 ‚îÇ
‚îÇ  ‚îú‚îÄ Remove T-SQL noise (DECLARE, SET, TRY/CATCH)           ‚îÇ
‚îÇ  ‚îú‚îÄ Remove administrative queries                           ‚îÇ
‚îÇ  ‚îú‚îÄ Remove utility SP calls (LogMessage, etc.)             ‚îÇ
‚îÇ  ‚îî‚îÄ Clean for SQLGlot compatibility                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 2: SQL Cleaning Engine (YAML Rules) [OPTIONAL]      ‚îÇ
‚îÇ  ‚îú‚îÄ Apply dialect-specific YAML rules                      ‚îÇ
‚îÇ  ‚îú‚îÄ Remove problematic T-SQL patterns                      ‚îÇ
‚îÇ  ‚îî‚îÄ Output: Cleaned SQL for SQLGlot                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 3: Statement Splitting                               ‚îÇ
‚îÇ  ‚îú‚îÄ Split on GO keyword (batch separator)                  ‚îÇ
‚îÇ  ‚îú‚îÄ Split on semicolons                                    ‚îÇ
‚îÇ  ‚îî‚îÄ Output: List of individual SQL statements              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 4: Per-Statement Parsing [BROKEN]                   ‚îÇ
‚îÇ  ‚îú‚îÄ For each statement:                                    ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ Try SQLGlot WARN mode                             ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ Extract tables from AST                           ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ If empty ‚Üí Regex fallback                         ‚îÇ
‚îÇ  ‚îî‚îÄ Combine results from all statements                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 5: Post-Processing                                   ‚îÇ
‚îÇ  ‚îú‚îÄ Remove system schemas (sys, dummy, etc.)               ‚îÇ
‚îÇ  ‚îú‚îÄ Remove temp tables (#temp, @variables)                 ‚îÇ
‚îÇ  ‚îú‚îÄ Remove non-persistent objects (CTEs, temp vars)        ‚îÇ
‚îÇ  ‚îî‚îÄ Deduplicate results                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PHASE 6: Confidence Calculation                            ‚îÇ
‚îÇ  ‚îú‚îÄ Compare found tables vs. expected (from DMV deps)      ‚îÇ
‚îÇ  ‚îú‚îÄ Completeness % = found / expected * 100                ‚îÇ
‚îÇ  ‚îî‚îÄ Map to score: 0, 75, 85, 100                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OUTPUT: Lineage Result                                     ‚îÇ
‚îÇ  {                                                           ‚îÇ
‚îÇ    "inputs": ["schema1.table1", "schema2.table2"],        ‚îÇ
‚îÇ    "outputs": ["schema3.table3"],                         ‚îÇ
‚îÇ    "confidence": 85,                                       ‚îÇ
‚îÇ    "sp_calls": ["schema.sp_name"],                        ‚îÇ
‚îÇ    "function_calls": ["schema.func_name"]                 ‚îÇ
‚îÇ  }                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Phase-by-Phase Analysis

### PHASE 1: SQL Preprocessing

**Location**: `quality_aware_parser.py:916-1085` (`_preprocess_ddl()`)

**Purpose**: Remove T-SQL-specific syntax that SQLGlot cannot parse

#### What Gets Removed/Replaced

1. **BEGIN TRY / END TRY blocks**
   ```sql
   -- Before
   BEGIN TRY
     INSERT INTO table1 ...
   END TRY
   BEGIN CATCH
     INSERT INTO ErrorLog ...
   END CATCH

   -- After
   BEGIN /* TRY */
     INSERT INTO table1 ...
   END /* TRY */
   BEGIN /* CATCH */
     SELECT 1;  -- Error handling removed
   END /* CATCH */
   ```

2. **Administrative Queries** (v4.1.2 critical fix)
   ```sql
   -- Before
   DECLARE @RowCount INT = (SELECT COUNT(*) FROM Table1)

   -- After
   DECLARE @RowCount INT = 1  -- Administrative query removed
   ```
   **Rationale**: Prevents COUNT queries from appearing as dependencies

3. **Variable Declarations**
   ```sql
   -- Before
   DECLARE @StartDate DATETIME = GETDATE()
   SET @Count = @Count + 1

   -- After
   [removed]
   ```

4. **Session Settings**
   ```sql
   -- Before
   SET NOCOUNT ON
   SET XACT_ABORT ON

   -- After
   [removed]
   ```

5. **Utility SP Calls** (82.2% of EXEC calls)
   ```sql
   -- Before
   EXEC [dbo].[LogMessage] 'Processing complete'
   EXEC [dbo].[spLastRowCount]

   -- After
   [removed]
   ```

6. **Post-COMMIT Code** (v4.1.0 fix)
   ```sql
   -- Before
   COMMIT TRANSACTION;
   INSERT INTO AuditLog ...  -- Cleanup code

   -- After
   COMMIT TRANSACTION;
   [rest removed]
   ```

7. **ROLLBACK Recovery Paths**
   ```sql
   -- Before
   ROLLBACK TRANSACTION;
   INSERT INTO ErrorLog ...

   -- After
   ROLLBACK TRANSACTION;
   SELECT 1;  -- Rollback path removed
   ```

#### Pattern Complexity

**Administrative Query Pattern** (Most Complex):
```python
# Handles nested parentheses like COUNT(*), MAX(col)
r'DECLARE\s+(@\w+)\s+(\w+(?:\([^\)]*\))?)\s*=\s*\((?:[^()]|\([^()]*\))*\)'
```

Uses balanced parentheses matching: `(?:[^()]|\([^()]*\))*`
- Matches 1 level of nesting
- Example: `(SELECT COUNT(*) FROM table)` ‚úÖ
- Example: `(SELECT MAX(col) FROM table)` ‚úÖ

#### Strengths
- ‚úÖ Comprehensive T-SQL noise removal
- ‚úÖ Preserves business logic (INSERT, UPDATE, DELETE, SELECT)
- ‚úÖ Improves SQLGlot success rate by ~27% (measured)
- ‚úÖ Removes 82.2% of EXEC calls (utilities only)

#### Weaknesses
- ‚ùå May remove too much (overly aggressive)
- ‚ùå Nested parentheses >1 level may break pattern
- ‚ùå Could accidentally remove business SPs if misidentified as utility

---

### PHASE 2: SQL Cleaning Engine (YAML Rules)

**Location**: `lineage_v3/core/rule_engine.py`

**Purpose**: Apply dialect-specific cleaning rules defined in YAML

**Status**: ‚úÖ Enabled by default (`enable_sql_cleaning=True`)

#### YAML Rule Structure

**Example Rule**: `lineage_v3/rules/tsql/10_remove_print.yaml`
```yaml
name: remove_print
description: Remove T-SQL PRINT statements
dialect: tsql
enabled: true
priority: 10

pattern: 'PRINT\s+.*'
replacement: ''

test_cases:
  - name: simple_print
    input: "PRINT 'Debug message'"
    expected: ""
```

#### Rule Engine Flow

```python
class RuleEngine:
    def apply_all(self, sql: str) -> str:
        # Load all enabled YAML rules
        rules = self._load_rules('lineage_v3/rules/tsql/')

        # Sort by priority
        rules.sort(key=lambda r: r['priority'])

        # Apply each rule
        for rule in rules:
            sql = re.sub(rule['pattern'], rule['replacement'], sql)

        return sql
```

#### Available Rules (v4.2.0)

Located in `lineage_v3/rules/tsql/`:
1. `10_remove_print.yaml` - Remove PRINT statements
2. `20_remove_comments.yaml` - Remove -- and /* */ comments
3. `30_normalize_whitespace.yaml` - Collapse multiple spaces
4. (Additional rules can be added without code changes)

#### Strengths
- ‚úÖ No code changes needed to add rules
- ‚úÖ Testable (each rule has test cases)
- ‚úÖ Priority-based ordering
- ‚úÖ Dialect-specific (can have different rules per SQL flavor)

#### Weaknesses
- ‚ùå Limited adoption (only 3 rules currently)
- ‚ùå Regex-only (cannot handle complex syntax)
- ‚ùå Measured impact: Only +27% SQLGlot success (not transformative)

---

### PHASE 3: Statement Splitting

**Location**: `quality_aware_parser.py:1087-1107` (`_split_statements()`)

**Purpose**: Break DDL into individual SQL statements for per-statement parsing

#### Algorithm

```python
def _split_statements(self, sql: str) -> List[str]:
    statements = []

    # Step 1: Split on GO (batch separator)
    batches = re.split(r'\bGO\b', sql, flags=re.IGNORECASE)

    for batch in batches:
        # Step 2: Split on semicolons
        parts = re.split(r';\s*(?=\S)', batch)

        for part in parts:
            part = part.strip()
            if part and not part.startswith('--'):
                statements.append(part)

    return statements
```

#### Example

**Input**:
```sql
DECLARE @count INT = 0;
GO
INSERT INTO table1
SELECT col1, col2
FROM source1
LEFT JOIN source2 ON source1.id = source2.id;
GO
SELECT @count = COUNT(*) FROM table1;
```

**Output**:
```python
[
    "DECLARE @count INT = 0",
    "INSERT INTO table1\nSELECT col1, col2\nFROM source1\nLEFT JOIN source2 ON source1.id = source2.id",
    "SELECT @count = COUNT(*) FROM table1"
]
```

#### ‚ö†Ô∏è **CRITICAL ISSUE**: Multi-Line Statement Fragmentation

**Problematic Case**:
```sql
INSERT INTO target
SELECT
  col1,
  col2
FROM source1
;
LEFT JOIN source2 ON source1.id = source2.id
```

After splitting on `;`:
```python
[
    "INSERT INTO target\nSELECT\n  col1,\n  col2\nFROM source1",  # ‚úÖ Valid
    "LEFT JOIN source2 ON source1.id = source2.id"                # ‚ùå Orphaned JOIN!
]
```

**Result**: JOIN clause becomes standalone "statement" with no SELECT context ‚Üí Not matched by regex patterns!

#### Why This Exists

- **For SQLGlot**: Parsing individual statements is easier than full DDL
- **For Regex**: Originally applied to full DDL, not statements
- **Problem**: Current code applies regex to statements (broken!)

#### Impact

- üü¢ **Helps SQLGlot**: Smaller chunks easier to parse
- üî¥ **Breaks Regex**: Loses context, orphaned JOIN clauses
- üî¥ **Root cause of ~25% missing dependencies**

---

### PHASE 4: Per-Statement Parsing [‚ùå BROKEN]

**Location**: `quality_aware_parser.py:741-765` (`_sqlglot_parse()`)

**Current Implementation** (v4.3.1 - BROKEN):

```python
# Try parsing each statement with optimized two-tier strategy
# Strategy: WARN first (fast), then regex fallback if empty results
for stmt in statements:
    stmt_sources = set()
    stmt_targets = set()

    # Phase 1: Try WARN mode (lenient - accepts broken SQL, fast)
    try:
        parsed = parse_one(stmt, dialect='tsql', error_level=ErrorLevel.WARN)
        if parsed:
            stmt_sources, stmt_targets = self._extract_from_ast(parsed)
    except Exception:
        pass  # SQLGlot failed completely, will use regex

    # Phase 2: If SQLGlot got nothing, use regex fallback
    if not stmt_sources and not stmt_targets:
        stmt_sources, stmt_targets, _, _ = self._regex_scan(stmt)

    sources.update(stmt_sources)
    targets.update(stmt_targets)

# If SQLGlot got nothing, fallback to regex on original DDL
if not sources and not targets:
    sources, targets, _, _ = self._regex_scan(original_ddl)
```

#### What Actually Happens

**For 99% of T-SQL stored procedures**:

1. **SQLGlot WARN Mode "Succeeds"**:
   ```
   'CREATE PROC [...] AS BEGIN ...' contains unsupported syntax.
   Falling back to parsing as a 'Command'.
   ```
   - Returns `<sqlglot.expressions.Create>` or `<sqlglot.expressions.Command>`
   - No exception raised
   - `_extract_from_ast()` called on Command node

2. **Table Extraction from Command Node**:
   ```python
   tables = parsed.find_all(exp.Table)
   # Returns: [] (empty) or only SP name from CREATE PROC
   ```
   - Command nodes have NO table information
   - `stmt_sources` and `stmt_targets` remain empty

3. **Regex Fallback Triggered**:
   ```python
   if not stmt_sources and not stmt_targets:  # TRUE!
       stmt_sources, stmt_targets, _, _ = self._regex_scan(stmt)
   ```
   - ‚úÖ Fallback IS triggered (condition is true)
   - ‚ùå But called on **individual statement**, not full DDL
   - ‚ùå Orphaned JOIN clauses not matched

4. **Final Fallback**:
   ```python
   if not sources and not targets:
       sources, targets, _, _ = self._regex_scan(original_ddl)
   ```
   - Only runs if ALL statements returned empty
   - Usually doesn't run because at least 1 statement found something

#### The Fatal Flaw

**WARN mode succeeds without exception** ‚Üí No error signal ‚Üí Looks like success ‚Üí Regex operates on fragmented statements ‚Üí Context lost ‚Üí Dependencies missed

---

### PHASE 5: Post-Processing

**Location**: Multiple methods

#### 5.1 System Schema Exclusion

**Method**: `_is_excluded(schema, table)`

**Excluded Schemas** (from config):
```python
self.excluded_schemas = {
    'sys', 'dummy', 'information_schema',
    'tempdb', 'master', 'msdb', 'model'
}
```

**Excluded Table Patterns**:
- Temp tables: `#temp`, `##global_temp`
- Table variables: `@table_var`

#### 5.2 Non-Persistent Object Removal

**Method**: `_identify_non_persistent_objects(ddl)` (v4.1.0)

**Purpose**: Remove objects that exist only during SP execution

**Patterns Detected**:
1. **CTEs (Common Table Expressions)**:
   ```sql
   WITH cte_name AS (SELECT ...)
   ```
   CTE name added to exclusion list

2. **Temp Tables**:
   ```sql
   CREATE TABLE #temp (...)
   INSERT INTO #temp ...
   ```
   `#temp` added to exclusion list

3. **Table Variables**:
   ```sql
   DECLARE @orders TABLE (...)
   INSERT INTO @orders ...
   ```
   `@orders` added to exclusion list

**Rationale**: These don't exist in the database catalog, shouldn't appear in lineage

#### 5.3 Deduplication

Results stored in Python `set()`:
- Automatic deduplication
- Order not preserved (not needed for lineage)

---

### PHASE 6: Confidence Calculation

**Location**: `quality_aware_parser.py:810-888` (`_calculate_simplified_confidence()`)

**Model**: v2.1.0 (4-value discrete)

#### Algorithm

```python
# Step 1: Get expected dependencies from DMV catalog
expected_tables = self._get_dmv_dependencies(object_id)
expected_count = len(expected_tables)

# Step 2: Count what we found
found_tables = set(inputs) | set(outputs)
found_count = len(found_tables)

# Step 3: Calculate completeness
if expected_count == 0:
    completeness = 100.0  # No dependencies expected
else:
    completeness = (found_count / expected_count) * 100

# Step 4: Map to discrete scores
if completeness >= 90:
    confidence = 100
elif completeness >= 70:
    confidence = 85
elif completeness >= 50:
    confidence = 75
else:
    confidence = 0
```

#### Special Cases

1. **Orchestrator SPs** (Only EXEC statements):
   - If SP only calls other SPs (no table deps)
   - Confidence = 100 (complete orchestrator)

2. **Parse Failures**:
   - If parsing raises exception
   - Confidence = 0
   - `parse_failure_reason` recorded

3. **No DMV Dependencies**:
   - Expected count = 0
   - If found > 0: Confidence = 100 (we found bonus tables!)
   - If found = 0: Confidence = 100 (nothing expected, nothing found)

#### Confidence Breakdown

```python
{
    "confidence": 85,
    "breakdown": {
        "expected_tables": 10,
        "found_tables": 8,
        "completeness_pct": 80.0,
        "missing_tables": ["schema.table1", "schema.table2"],
        "primary_source": "parser"  # or "dmv" or "hint"
    }
}
```

#### Current Problem

- Expected: 2-10 tables per SP (from DMV)
- Found: 0 tables per SP (parser broken)
- Completeness: 0%
- **Result: 99% of SPs get confidence = 0**

---

## Architecture Evolution

### v4.0.0 - Original Regex-First Design (WORKED)

```
Input DDL
    ‚Üì
Preprocessing (remove T-SQL noise)
    ‚Üì
Regex Scan (BASELINE - always succeeds)
    ‚îú‚îÄ sources = [...]
    ‚îú‚îÄ targets = [...]
    ‚îî‚îÄ confidence baseline established
    ‚Üì
SQLGlot with RAISE mode (STRICT)
    ‚îú‚îÄ Success? Combine with regex (best of both)
    ‚îî‚îÄ Exception? Use regex baseline (guaranteed fallback)
    ‚Üì
Confidence calculation
    ‚Üì
Output (95% success rate)
```

**Key**: Regex always ran on **full DDL**, not statements!

---

### v4.1.0 - SQLGlot Enhancement (Still Good)

```
Added:
- SQL Cleaning Engine (YAML rules)
- Non-persistent object detection
- Better preprocessing patterns

Result: +27% SQLGlot success
Overall: Still ~95% success rate
```

---

### v4.2.0 - WARN Mode "Breakthrough" (CATASTROPHIC)

**Commit**: `27a3d63 - BREAKTHROUGH: WARN mode for both paths simplifies architecture dramatically`

**Changes**:
```diff
- parsed = parse_one(stmt, dialect='tsql', error_level=ErrorLevel.RAISE)
+ parsed = parse_one(stmt, dialect='tsql', error_level=None)  # WARN mode
```

**Removed**:
- Proper exception handling
- Regex baseline guarantee
- SQLGlot failure detection

**Result**:
- SQLGlot "succeeds" with useless Command nodes
- Regex fallback happens but on broken statement fragments
- **Success rate drops from 95% to 1%**

---

### v4.3.0 - Phantom Objects & UDF Support (Attempted Fix)

**Added**:
- Phantom object detection (v4.3.0) ‚úÖ Works
- Function call detection ‚úÖ Works
- Performance optimizations ‚úÖ Works

**Attempted Parser Fix** (v4.3.1 - Today):
```python
# Two-tier strategy
1. Try WARN mode
2. Regex fallback if empty
```

**Result**: Still broken because statement splitting issue remains

---

## Current Issues - Complete List

### Critical Issues (Blocking)

#### Issue 1: ‚ùå **WARN Mode Silent Failure**

**Impact**: HIGH - Root cause of 99% failure rate

**Details**:
- SQLGlot WARN mode returns Command nodes with zero tables
- No exception raised ‚Üí looks like success
- Regex fallback triggers but operates on fragmented statements

**Evidence**:
```
‚úÖ SQLGlot WARN mode succeeded on full DDL
Tables found in full AST: 1
  - CONSUMPTION_ClinOpsFinance.spLoadFactLaborCostForEarnedValue_Post

Expected: ~10 tables
Found: 1 (the SP itself)
```

---

#### Issue 2: ‚ùå **Statement Splitting Breaks Context**

**Impact**: HIGH - Causes ~25% of dependencies to be missed

**Details**:
- Multi-line SQL split on semicolons
- JOIN clauses become orphaned statements
- Regex patterns no longer match without SELECT context

**Example**:
```sql
-- Original
INSERT INTO target
SELECT col1, col2
FROM source1;
LEFT JOIN source2 ON source1.id = source2.id

-- After split
["INSERT INTO target SELECT col1, col2 FROM source1",
 "LEFT JOIN source2 ON source1.id = source2.id"]  ‚Üê Orphaned!
```

**Evidence**:
- Pattern `r'\bLEFT\s+(?:OUTER\s+)?JOIN\s+\[?(\w+)\]?\.\[?(\w+)\]?'` exists
- But `CadenceBudget_LaborCost_PrimaContractUtilization_Junc` not found
- SQL contains: `left join [CONSUMPTION_ClinOpsFinance].[CadenceBudget...] ju on`
- **Conclusion**: Pattern correct, but context lost during splitting

---

### High Priority Issues

#### Issue 3: ‚ö†Ô∏è **Parser Timeout**

**Impact**: HIGH - 3+ minute timeout on 515 SPs

**Details**:
- SQLGlot WARN mode processes slowly
- 515 SPs √ó ~2 seconds each = 17+ minutes
- API timeout at 3 minutes

**Evidence**: `test_upload.sh` output:
```
Status:  (attempt 1/90)
...
Status:  (attempt 90/90)
‚è±Ô∏è Timeout waiting for job
```

---

#### Issue 4: ‚ö†Ô∏è **Over-Aggressive Function Pattern**

**Impact**: MEDIUM - May create false positives

**Pattern**:
```python
r'\b\[?(\w+)\]?\.\[?(\w+)\]?\s*\('  # Catches ANY schema.name(
```

**Problem**: Too broad, may match non-functions

**Example False Positives**:
- `CASE WHEN schema.column(...) THEN` (column, not function)
- `schema.procedure()` as column alias?

**Mitigation**: Built-in function exclusion list helps

---

### Medium Priority Issues

#### Issue 5: ‚ö†Ô∏è **Missing CROSS JOIN Pattern**

**Impact**: LOW - Rare pattern, but incomplete

**Missing**:
```python
r'\bCROSS\s+JOIN\s+\[?(\w+)\]?\.\[?(\w+)\]?'
```

**Frequency**: <1% of queries use CROSS JOIN

---

#### Issue 6: ‚ö†Ô∏è **No CTE Source Detection**

**Impact**: LOW-MEDIUM - CTEs are common

**Current**: CTEs identified for exclusion
**Missing**: Tables **inside** CTEs not extracted

**Example**:
```sql
WITH monthly_sales AS (
    SELECT * FROM sales_table  ‚Üê Not extracted!
)
SELECT * FROM monthly_sales
```

**Result**: `sales_table` dependency missed

---

#### Issue 7: ‚ö†Ô∏è **No Subquery Support**

**Impact**: LOW - Most subqueries caught via FROM patterns

**Example**:
```sql
SELECT *
FROM table1
WHERE id IN (
    SELECT id FROM table2  ‚Üê May be missed
)
```

**Current**: Outer FROM catches `table1`, subquery `table2` may be missed

---

### Low Priority Issues

#### Issue 8: ‚ÑπÔ∏è **Character Set Limitation**

**Pattern**: `\w+` only matches alphanumeric + underscore

**Missing**:
- Hyphens: `my-table-name`
- Spaces (quoted identifiers): `[My Table Name]`

**Frequency**: Rare (violates SQL naming conventions)

---

#### Issue 9: ‚ÑπÔ∏è **Duplicate Results**

**Impact**: NONE (auto-deduplicated by set)

**Evidence**:
```
FROM tables found: 4
  - [CONSUMPTION_POWERBI].[FactLaborCostForEarnedValue]
  - [CONSUMPTION_POWERBI].[FactLaborCostForEarnedValue]  ‚Üê Duplicate
```

**Cause**: Pattern matches same table multiple times in SQL

---

## Test Results

### Test Database Statistics

- **Total Objects**: 1,067
  - Stored Procedures: 515
  - Tables: 350
  - Views: 150
  - Functions: 52

- **Total Dependencies** (from DMV): 732
  - Average per SP: ~1.4 dependencies

### Parsing Results (Current - BROKEN)

```
Total SPs parsed: 515
Successful (confidence > 0): 2 (0.4%)
Failed (confidence = 0): 513 (99.6%)

Average parsing time per SP: 0.35 seconds
Total parsing time: 180+ seconds (TIMEOUT)

Average inputs per SP: 0.0
Average outputs per SP: 0.0
```

### Specific Test Case: spLoadFactLaborCostForEarnedValue_Post

| Component | Expected | SQLGlot WARN | Regex (Statement) | Regex (Full DDL) |
|-----------|----------|--------------|-------------------|------------------|
| Target | FactLaborCostForEarnedValue_Post | ‚ùå 0 | ‚úÖ Found | ‚úÖ Found |
| Source 1 | FactLaborCostForEarnedValue | ‚ùå 0 | ‚úÖ Found | ‚úÖ Found |
| Source 2 | CadenceBudget...Junc | ‚ùå 0 | ‚ùå **MISSING** | ‚úÖ Would find |
| Source 3 | DateRangeMonthClose_Config | ‚ùå 0 | ‚úÖ Found | ‚úÖ Found |
| Source 4 | DimDate | ‚ùå 0 | ‚úÖ Found | ‚úÖ Found |

**Conclusion**:
- SQLGlot WARN: 0/5 tables (0%)
- Regex on statements: 3/5 tables (60%)
- Regex on full DDL: 5/5 tables (100%) ‚Üê **THIS IS THE SOLUTION!**

---

## Problem Statement Summary

### Current State: üî¥ CRITICAL FAILURE

**Performance Metrics**:
- ‚úÖ **Historical Success Rate** (v4.0.0 - v4.1.0): 95%
- ‚ùå **Current Success Rate** (v4.2.0 - v4.3.1): 1% (2/515 SPs)
- ‚è±Ô∏è **Parsing Time**: 180+ seconds (timeout)
- üìä **User Impact**: Empty dependency graphs, no usable lineage data

### Root Causes Identified

1. **SQLGlot WARN Mode Silent Failure**
   - Returns Command nodes with zero table information
   - No exceptions raised, appears to succeed
   - Introduced in commit `27a3d63` ("BREAKTHROUGH: WARN mode")

2. **Statement Splitting Context Loss**
   - JOIN clauses separated from SELECT statements
   - Regex fallback operates on fragments, not full context
   - Example: Missing `CadenceBudget...Junc` table in test SP

3. **Architecture Regression**
   - Original design: Regex-first (full DDL) ‚Üí SQLGlot enhancement
   - Current design: SQLGlot-first (statements) ‚Üí Regex fallback
   - Lost guaranteed baseline from regex on full DDL

### What We Tried (Architecture Evolution)

#### ‚úÖ v4.0.0 - Original Design (95% Success)
- Regex scan on **full DDL** (guaranteed baseline)
- SQLGlot RAISE mode on statements (strict, fails fast)
- Exception-based fallback to regex
- **Result**: 95% success rate

#### ‚úÖ v4.1.0 - SQLGlot Enhancement (Still 95%)
- Added SQL Cleaning Engine (YAML rules)
- Non-persistent object detection
- Administrative query removal
- **Result**: +27% SQLGlot success, maintained 95% overall

#### ‚ùå v4.2.0 - WARN Mode "Breakthrough" (Catastrophic)
- Changed SQLGlot to WARN mode (error_level=None)
- Removed exception handling
- Removed regex baseline guarantee
- **Result**: 95% ‚Üí 1% success rate (regression)

#### ‚ö†Ô∏è v4.3.0 - Feature Additions (Parser Still Broken)
- Added phantom object detection ‚úÖ Works
- Added function call detection ‚úÖ Works
- Added performance optimizations ‚úÖ Works
- Attempted two-tier parser fix ‚ùå Still broken

#### ‚ö†Ô∏è v4.3.1 - Today (In Analysis)
- Deep debugging with analyze_sp.py
- Test case validation (spLoadFactLaborCostForEarnedValue_Post)
- Identified that regex on full DDL would find 5/5 tables
- Current implementation finds 0/5 (SQLGlot) or 3/5 (regex on statements)

### Evidence from Testing

**Test Case**: `spLoadFactLaborCostForEarnedValue_Post`

| Approach | Tables Found | Success Rate | Status |
|----------|--------------|--------------|--------|
| SQLGlot WARN mode | 0/5 | 0% | ‚ùå Useless |
| Regex on statements | 3/5 | 60% | ‚ö†Ô∏è Context loss |
| Regex on full DDL | 5/5 | 100% | ‚úÖ Would work |

**Missing Table**: `CadenceBudget_LaborCost_PrimaContractUtilization_Junc`
- **Reason**: LEFT JOIN clause isolated from SELECT context by statement splitting
- **Pattern exists**: `r'\bLEFT\s+(?:OUTER\s+)?JOIN\s+\[?(\w+)\]?\.\[?(\w+)\]?'` ‚úÖ
- **Execution fails**: Pattern runs on orphaned JOIN fragment ‚ùå

### Additional Issues Identified

1. **Job Tracking Problem**: API job status returns 404 even after processing completes
2. **Parse Timeout**: 515 SPs take 180+ seconds (should be <30 seconds)
3. **Duplicate Detection**: Same table matched multiple times by regex
4. **Missing Patterns**: CROSS JOIN, basic CTEs not detected
5. **Function Pattern**: May incorrectly match `CASE WHEN ... schema.table()`

### Technical Debt

- Regex patterns comprehensive but execution flow broken
- YAML rule engine underutilized (only 2-3 active rules)
- SQLGlot integration ineffective with WARN mode
- Preprocessing removes too much or too little (balance needed)
- No unit tests for individual parsing phases

---

**Report End**

*Generated with analyze_sp.py test results*
*Based on 515 real stored procedures from production Synapse database*
*Document Purpose: Problem statement and historical analysis, not task list*
